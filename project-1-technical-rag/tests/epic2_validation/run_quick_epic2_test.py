#!/usr/bin/env python3
"""
Quick Epic 2 Test Runner
========================

Simple test runner for basic Epic 2 validation.
Runs essential tests quickly without comprehensive validation.

Usage:
    python run_quick_epic2_test.py
    python run_quick_epic2_test.py --test configuration
    python run_quick_epic2_test.py --test subcomponent
"""

import sys
import argparse
import logging
from pathlib import Path

# Add project root to Python path
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# Import Epic 2 test modules
from test_epic2_configuration_validation_new import Epic2ConfigurationValidator
from test_epic2_subcomponent_integration_new import (
    Epic2SubComponentIntegrationValidator,
)
from epic2_test_utilities import Epic2TestEnvironment

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)


def run_environment_check():
    """Quick environment validation."""
    print("ğŸ” Checking Epic 2 test environment...")

    env_results = Epic2TestEnvironment.validate_environment()

    if env_results["overall"]["ready"]:
        print("âœ… Environment ready for Epic 2 testing")
        return True
    else:
        print("âŒ Environment issues detected:")
        for issue in env_results["overall"]["issues"]:
            print(f"  - {issue}")
        return False


def run_configuration_test():
    """Run configuration validation test."""
    print("\nğŸ”§ Running configuration validation...")

    try:
        validator = Epic2ConfigurationValidator()
        results = validator.run_all_validations()

        score = results.get("overall_score", 0)
        passed = results.get("passed_tests", 0)
        total = results.get("total_tests", 0)

        if score >= 80:
            print(f"âœ… Configuration validation: {score:.1f}% ({passed}/{total})")
        else:
            print(f"âŒ Configuration validation: {score:.1f}% ({passed}/{total})")

            # Show first few errors
            if results.get("validation_errors"):
                print("  Issues:")
                for error in results["validation_errors"][:3]:
                    print(f"    - {error}")

        return score >= 80

    except Exception as e:
        print(f"âŒ Configuration test failed: {e}")
        return False


def run_subcomponent_test():
    """Run sub-component integration test."""
    print("\nğŸ”— Running sub-component integration...")

    try:
        validator = Epic2SubComponentIntegrationValidator()
        results = validator.run_all_validations()

        score = results.get("overall_score", 0)
        passed = results.get("passed_tests", 0)
        total = results.get("total_tests", 0)

        if score >= 80:
            print(f"âœ… Sub-component integration: {score:.1f}% ({passed}/{total})")
        else:
            print(f"âŒ Sub-component integration: {score:.1f}% ({passed}/{total})")

            # Show first few errors
            if results.get("validation_errors"):
                print("  Issues:")
                for error in results["validation_errors"][:3]:
                    print(f"    - {error}")

        return score >= 80

    except Exception as e:
        print(f"âŒ Sub-component test failed: {e}")
        return False


def main():
    """Main entry point for quick Epic 2 test."""
    parser = argparse.ArgumentParser(description="Quick Epic 2 Test Runner")

    parser.add_argument(
        "--test",
        choices=["environment", "configuration", "subcomponent", "all"],
        default="all",
        help="Specific test to run",
    )

    args = parser.parse_args()

    print("ğŸš€ Epic 2 Quick Test Runner")
    print("=" * 40)

    results = []

    # Environment check (always run)
    env_ok = run_environment_check()
    results.append(("Environment", env_ok))

    if not env_ok:
        print("\nâŒ Environment not ready. Please fix issues before running tests.")
        sys.exit(1)

    # Run requested tests
    if args.test in ["configuration", "all"]:
        config_ok = run_configuration_test()
        results.append(("Configuration", config_ok))

    if args.test in ["subcomponent", "all"]:
        subcomp_ok = run_subcomponent_test()
        results.append(("Sub-component", subcomp_ok))

    # Summary
    print("\nğŸ“Š Quick Test Summary")
    print("-" * 30)

    passed_tests = sum(1 for _, result in results if result)
    total_tests = len(results)

    for test_name, result in results:
        status = "âœ… PASS" if result else "âŒ FAIL"
        print(f"{test_name}: {status}")

    success_rate = (passed_tests / total_tests) * 100
    print(f"\nOverall: {success_rate:.1f}% ({passed_tests}/{total_tests})")

    if success_rate >= 100:
        print("ğŸ‰ All quick tests passed! Epic 2 basic functionality verified.")
        sys.exit(0)
    elif success_rate >= 80:
        print("âœ… Most tests passed. Epic 2 mostly functional with minor issues.")
        sys.exit(0)
    else:
        print("âŒ Multiple test failures. Epic 2 needs attention.")
        sys.exit(1)


if __name__ == "__main__":
    main()
