# Epic 2 Enhanced RAG Configuration - HuggingFace API Integration
# This configuration uses Epic 2 features with HuggingFace API for LLM generation
# All Epic 2 capabilities preserved: neural reranking, graph enhancement, analytics

# Document processor for handling input files
document_processor:
  type: "hybrid_pdf"
  config:
    chunk_size: 1024
    chunk_overlap: 128

# Embedding generator for converting text to vectors  
embedder:
  type: "modular"
  config:
    model:
      type: "sentence_transformer"
      config:
        model_name: "sentence-transformers/multi-qa-MiniLM-L6-cos-v1"
        device: "auto"
        normalize_embeddings: true
    batch_processor:
      type: "dynamic"
      config:
        initial_batch_size: 64
        max_batch_size: 256
        optimize_for_memory: false
    cache:
      type: "memory"
      config:
        max_entries: 100000
        max_memory_mb: 1024

# Epic 2 ModularUnifiedRetriever with Enhanced Sub-components
retriever:
  type: "modular_unified"  # Use ModularUnifiedRetriever
  config:
    vector_index:
      type: "faiss"
      config:
        index_type: "IndexFlatIP"
        normalize_embeddings: true
        metric: "cosine"
    
    sparse:
      type: "bm25"
      config:
        k1: 1.2
        b: 0.75
        lowercase: true
        preserve_technical_terms: true
    
    # Epic 2 Feature: Graph Enhanced Fusion
    fusion:
      type: "graph_enhanced_rrf"  # Use GraphEnhancedRRFFusion for Epic 2
      config:
        k: 60
        weights:
          dense: 0.4    # Reduced to accommodate graph
          sparse: 0.3   # Maintained
          graph: 0.3    # NEW: Graph-based retrieval weight
        graph_enabled: true
        similarity_threshold: 0.65
        max_connections_per_document: 15
        use_pagerank: true
        pagerank_damping: 0.85
    
    # Epic 2 Feature: Neural Reranking
    reranker:
      type: "neural"  # Use NeuralReranker for Epic 2
      config:
        enabled: true
        model_name: "cross-encoder/ms-marco-MiniLM-L6-v2"
        device: "auto"
        batch_size: 32
        max_length: 512
        max_candidates: 100
        models:
          default_model:
            name: "cross-encoder/ms-marco-MiniLM-L6-v2"
            device: "auto"
            batch_size: 32
            max_length: 512
        default_model: "default_model"

# HuggingFace API Answer Generation Strategy
answer_generator:
  type: "adaptive_modular"
  config:
    # HuggingFace API Configuration
    llm_client:
      type: "huggingface"  # Use HuggingFace adapter
      config:
        # HuggingFace API settings
        api_token: "${HF_TOKEN}"  # Set via environment variable
        model_name: "microsoft/DialoGPT-medium"  # Primary model
        use_chat_completion: true
        timeout: 30
        temperature: 0.3
        max_tokens: 1024
        
        # Fallback models if primary fails
        fallback_models:
          - "google/gemma-2-2b-it"
          - "Qwen/Qwen2.5-1.5B-Instruct"
          - "google/flan-t5-small"
    
    # Legacy parameters for backward compatibility
    model_name: "microsoft/DialoGPT-medium"
    api_token: "${HF_TOKEN}"
    temperature: 0.3
    max_tokens: 1024
    use_ollama: false
    ollama_url: "http://localhost:11434"
    use_inference_providers: false
    enable_adaptive_prompts: false
    enable_chain_of_thought: false
    confidence_threshold: 0.85
    
    # Enhanced prompt configuration for technical documentation
    prompt_builder:
      type: "simple"
      config:
        max_context_length: 12000
        include_instructions: true
        citation_style: "inline"
        template: |
          You are an expert technical assistant specializing in RISC-V architecture and computer systems.
          
          Context Documents:
          {context}
          
          Question: {query}
          
          Instructions:
          - Provide a comprehensive, detailed technical answer based ONLY on the provided context
          - Include technical specifications, encoding details, and implementation information when available
          - Explain concepts step-by-step with technical depth appropriate for engineers
          - Cover related concepts and connections mentioned in the context
          - Include specific examples, instruction formats, or implementation details when present
          - Be thorough and detailed - technical documentation requires comprehensive coverage
          - If multiple aspects are mentioned in the context, address all of them
          - ALWAYS include citations using [Document X] format after every factual claim
          - Every technical specification, instruction format, or implementation detail must be cited
          - Use multiple citations when information comes from several sources: [Document 1, Document 2]
          
          Answer:

# Global settings
global_settings:
  environment: "testing"
  log_level: "info"