#!/bin/bash
set -e

echo "ğŸš€ Starting Technical RAG Assistant..."

# Start Ollama service in background
echo "ğŸ“¦ Starting Ollama service..."
ollama serve &
OLLAMA_PID=$!

# Wait for Ollama to be ready
echo "â³ Waiting for Ollama to be ready..."
sleep 5

# Check if model exists, if not download it
echo "ğŸ” Checking for Llama 3.2 model..."
if ! ollama list | grep -q "llama3.2:3b"; then
    echo "â¬‡ï¸  Downloading Llama 3.2 (3B) model (this may take a few minutes)..."
    ollama pull llama3.2:3b
    echo "âœ… Model downloaded successfully!"
else
    echo "âœ… Llama 3.2 model already available!"
fi

# Verify model is ready
echo "ğŸ”§ Verifying model availability..."
if ollama list | grep -q "llama3.2:3b"; then
    echo "âœ… Ollama and Llama 3.2 ready!"
else
    echo "âŒ Model verification failed!"
    exit 1
fi

# Start Streamlit app
echo "ğŸŒŸ Starting Streamlit application..."
exec streamlit run app.py \
    --server.port=8501 \
    --server.address=0.0.0.0 \
    --server.headless=true \
    --server.enableCORS=false \
    --server.enableXsrfProtection=false